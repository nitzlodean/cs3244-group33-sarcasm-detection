{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"sGXWwsnon3rk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764435940006,"user_tz":-480,"elapsed":22742,"user":{"displayName":"zd","userId":"01712767252590713506"}},"outputId":"8c45dd9a-1b21-4231-9df0-2b7dc576aecf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RQhmAcKDn_Gj","executionInfo":{"status":"ok","timestamp":1764436015685,"user_tz":-480,"elapsed":21492,"user":{"displayName":"zd","userId":"01712767252590713506"}}},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_csv(\n","    \"/content/drive/MyDrive/cs3244/dataset/train-balanced.csv.bz2\",\n","    compression=\"bz2\",\n","    sep=\"\\t\",\n","    header=None  # if there’s no header row\n",")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"uleJ3qL4oMNy","executionInfo":{"status":"ok","timestamp":1764436020431,"user_tz":-480,"elapsed":5,"user":{"displayName":"zd","userId":"01712767252590713506"}}},"outputs":[],"source":["# assign column names for clarity\n","df.columns = [\n","    \"label\", \"text\", \"author\", \"subreddit\",\n","    \"upvotes\", \"downvotes\", \"score\",\n","    \"date\", \"timestamp\", \"comment\"\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mS-xPhhoofDK"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sentence_transformers import SentenceTransformer\n","import torch\n","from tqdm import tqdm\n","\n","def embed_text(df, text_col=\"text\", model_name=\"all-MiniLM-L6-v2\", batch_size=64, device=None):\n","    \"\"\"\n","    Embeds text from a dataframe column using a pretrained SentenceTransformer model.\n","\n","    Parameters\n","    ----------\n","    df : pd.DataFrame\n","        Input dataframe containing the text column.\n","    text_col : str\n","        Name of the column containing text to embed.\n","    model_name : str\n","        Pretrained model name from Hugging Face (default = 'all-MiniLM-L6-v2').\n","    batch_size : int\n","        Batch size for encoding (higher = faster but more memory).\n","    device : str or None\n","        'cuda' for GPU, 'cpu' for CPU, None = auto-detect.\n","\n","    Returns\n","    -------\n","    np.ndarray\n","        Embedding matrix of shape (n_samples, embedding_dim).\n","    \"\"\"\n","    # Load model\n","    model = SentenceTransformer(model_name, device=device)\n","\n","    # Extract text\n","    texts = df[text_col].astype(str).tolist()\n","\n","    # Encode in batches\n","    embeddings = model.encode(\n","        texts,\n","        batch_size=batch_size,\n","        show_progress_bar=True,\n","        convert_to_numpy=True,\n","        normalize_embeddings=True  # L2 normalize vectors\n","    )\n","\n","    return embeddings\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0PZmcS3SoyoS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764435233256,"user_tz":-480,"elapsed":2057874,"user":{"displayName":"zd","userId":"01712767252590713506"}},"outputId":"8d3224cc-6065-4e3a-e08c-08a16eca24b4"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 8795/8795 [34:14<00:00,  4.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Embeddings saved incrementally to: /content/drive/MyDrive/cs3244/features/embeddings_memmap.npy\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sentence_transformers import SentenceTransformer\n","import torch\n","from tqdm import tqdm\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = SentenceTransformer(\"all-mpnet-base-v2\", device=device)\n","\n","batch_size = 128\n","save_path = \"/content/drive/MyDrive/cs3244/features/embeddings_memmap.npy\"\n","\n","n_samples = len(df)\n","embedding_dim = model.get_sentence_embedding_dimension()\n","\n","# Create memory-mapped file (doesn't load all in RAM)\n","embeddings = np.memmap(save_path, dtype='float32', mode='w+', shape=(n_samples, embedding_dim))\n","\n","for start_idx in tqdm(range(0, n_samples, batch_size)):\n","    end_idx = min(start_idx + batch_size, n_samples)\n","    batch_texts = df[\"text\"].iloc[start_idx:end_idx].astype(str).tolist()\n","\n","    batch_embeddings = model.encode(\n","        batch_texts,\n","        convert_to_numpy=True,\n","        normalize_embeddings=True\n","    )\n","\n","    embeddings[start_idx:end_idx] = batch_embeddings\n","\n","# Flush to disk\n","embeddings.flush()\n","print(\"Embeddings saved incrementally to:\", save_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":380,"status":"ok","timestamp":1764435237551,"user":{"displayName":"zd","userId":"01712767252590713506"},"user_tz":-480},"id":"-OrmCcJuqlvS","outputId":"adc530da-336a-4f86-c800-2eb510921893"},"outputs":[{"output_type":"stream","name":"stdout","text":["Embeddings shape: (1125678, 768)\n"]}],"source":["import numpy as np\n","\n","n_samples = len(df)  # number of rows in your dataset\n","embedding_dim = 768   # dimension of embeddings (all-mpnet-base-v2)\n","\n","embeddings = np.memmap(\n","    \"/content/drive/MyDrive/cs3244/features/embeddings_memmap.npy\",\n","    dtype='float32',\n","    mode='r',\n","    shape=(n_samples, embedding_dim)\n",")\n","\n","print(\"Embeddings shape:\", embeddings.shape)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"uT3O0zziC2VH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"39a9548e-f823-4c9d-d70b-d63e4ff8ad07","executionInfo":{"status":"ok","timestamp":1764436697589,"user_tz":-480,"elapsed":666094,"user":{"displayName":"zd","userId":"01712767252590713506"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Embeddings shape: (1125678, 768)\n","Reduced embeddings shape: (1125678, 100)\n","Cross-Validation Accuracies: [0.65295199 0.65245896 0.6538892  0.65363449 0.65209319]\n","Mean CV Accuracy: 0.6530 ± 0.0007\n"]}],"source":["import numpy as np\n","from sklearn.decomposition import IncrementalPCA\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import StratifiedKFold, cross_val_score\n","\n","# ----- PARAMETERS -----\n","n_samples = len(df)\n","embedding_dim = 768\n","pca_components = 100    # reduce to 100 dimensions\n","batch_size_pca = 1024   # batch size for incremental PCA\n","cv_folds = 5            # cross-validation folds\n","\n","# ----- LOAD EMBEDDINGS -----\n","embeddings = np.memmap(\n","    \"/content/drive/MyDrive/cs3244/features/embeddings_memmap.npy\",\n","    dtype='float32',\n","    mode='r',\n","    shape=(n_samples, embedding_dim)\n",")\n","print(\"Embeddings shape:\", embeddings.shape)\n","\n","# ----- LOAD LABELS -----\n","y = df[\"label\"].values  # 0/1 sarcasm labels\n","\n","# ----- INCREMENTAL PCA (batch-safe) -----\n","ipca = IncrementalPCA(n_components=pca_components, batch_size=batch_size_pca)\n","for start in range(0, n_samples, batch_size_pca):\n","    end = min(start + batch_size_pca, n_samples)\n","    ipca.partial_fit(embeddings[start:end])\n","\n","# Transform embeddings in batches and store in smaller array\n","X_reduced = np.zeros((n_samples, pca_components), dtype=np.float32)\n","for start in range(0, n_samples, batch_size_pca):\n","    end = min(start + batch_size_pca, n_samples)\n","    X_reduced[start:end] = ipca.transform(embeddings[start:end])\n","\n","print(\"Reduced embeddings shape:\", X_reduced.shape)\n","\n","# ----- LOGISTIC REGRESSION + STRATIFIED CV -----\n","clf = LogisticRegression(\n","    max_iter=200,\n","    solver='liblinear',\n","    class_weight='balanced'\n",")\n","\n","cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n","scores = cross_val_score(clf, X_reduced, y, cv=cv, scoring='accuracy')\n","\n","print(\"Cross-Validation Accuracies:\", scores)\n","print(\"Mean CV Accuracy: {:.4f} ± {:.4f}\".format(np.mean(scores), np.std(scores)))\n"]},{"cell_type":"code","source":["import joblib\n","model_file = \"/content/drive/MyDrive/cs3244/models/sarcasm_logreg_model_embeds.pkl\"\n","joblib.dump(clf, model_file)\n","print(f\"Saved trained model to {model_file}\")"],"metadata":{"id":"T6qs4Cf4Y9t5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764436788512,"user_tz":-480,"elapsed":13,"user":{"displayName":"zd","userId":"01712767252590713506"}},"outputId":"fd3b1990-4686-43b4-9cf8-4fae42258ed5"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved trained model to /content/drive/MyDrive/cs3244/models/sarcasm_logreg_model_embeds.pkl\n"]}]},{"cell_type":"markdown","metadata":{"id":"W7L58IpvnLhF"},"source":["BEEP"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}